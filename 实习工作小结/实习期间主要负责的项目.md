实习期间主要负责的项目：

#### 大模型VIP漏洞情报项目

001 将原始的cpe 漏洞情报数据（vip_cpe）插入到milvus向量数据库中

002 使用大模型和Prompt engineering对vip_vuln的漏洞情报进行提取

输入：json格式的漏洞情报：

```json
{'vuln_name': 'DELL EMC AppSync 安全漏洞', 
 'vuln_desc': 'DELL EMC AppSync是美国戴尔DELL公司的一个复制数据管理软件提供一种由 SLA 驱动的简单自助服务方式来保护恢复和克隆关键的Microsoft 与 Oracle 应用程序以及 VMware 环境DELL EMC AppSync 存在安全漏洞该漏洞源于Dell EMC AppSync版本3.9至4.3包含过度认证尝试限制不当漏洞可从UI和CLI加以利用攻击者可利用该漏洞导致密码暴力强制', 
 'effect_scope': None} 
```

003 将客户的cpe情报与向量数据库中的数据进行匹配，并返回top50相似的数据，然后将这50个CPE数据进行版本号从低到高的排序。

004 针对上述排序的CPE顺序，使用大模型对符合版本号的CPE数据再一次进行筛选，得到最终准确的CPE结果。

#### 关于大模型的Fine-Tuning

001 收集安全对齐相关数据，并且对QWen-7B模型进行微调，使用自我认知数据、安全对齐数据、通用预料对LLM进行训练，避免大模型对通用语料回答的丧失。

其中安全对齐数据主要使用的是https://www.modelscope.cn/datasets/Shanghai_AI_Laboratory/SafeMTData/dataPeview中的多轮对话数据，首先将多轮对话的内容翻译成中文，然后中英文一起进行训练。

002数据格式要改为和qwen微调一致的数据格式：

```json
[
    {
        "type": "chatml",
        "messages": [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "What is the role of Political Action Committees (PACs) in the American political system?"},
            {"role": "assistant", "content": "政治行动委员会（PACs）在美国政治体系中扮演什么角色？"},
            {"role": "user", "content": "Political Action Committees (PACs) play a significant role in the American political system by providing a legal mechanism for individuals and organizations to pool their financial resources and contribute to political campaigns."},
            {"role": "assistant", "content": "政治行动委员会（PACs）在美国政治体系中发挥着重要作用，为个人和组织提供了一个合法机制，以汇集他们的财务资源并为政治竞选提供资金。"}
        ],
        "source": "self-made"
    }
]
```

使其达到安全对齐的效果，然后对微调的结果进行进一步的评判，使用LLama Guard3. 完成自我认知和安全对齐的训练，完成相应的额测试报告

003 完成gradio展示界面，展示大模型的自我认知和安全对齐效果，完成交付报告。

#### 大模型对抗样本prompt生成

001  使用prompt engineering，生成不同种类的对抗样本（比如在不同医学场景下的小分类），然后将得到的对抗样本prompt送入到大模型中进行安全性测试，避免大模型输出违法违规的结果。

#### CLIP/BLIP的使用

001 首先将text和图像分别插入到两个milvus数据库中，分别存储text和image的向量。对于两者向量的维度，必须是使用CLIP或者BLIP已训练的模型进行embedding嵌入，不可以选择其他虽然维度相同但是非官方的方法，因为这些方法并未得到训练，也不会得到对应的图像文本对的loss最小。



在使用BLIP存图像向量的时候 是否要用池化操作？

现在是一个二维矩阵

002 输入图像和query，然后将图像转化为向量，之后分别对图像数据库和文本数据库进行召回，进行去重（合并操作），得到输出的text。

003 进行对召回结果的评估。

注意：在插入到milvus数据库中的时候，若没有提前对collection的filed字段进行定义，那么insert方法时需要”id“ ”vector“ ”text“这三个字段。不要随意改动字段名，不然会报错。pymilvus.exceptions.ParamError: <ParamError: (code=1, message=Field vector don't match in entities[0])>  

```python
[
    {"id": id, "vector": image_vectors, "text": "medical text description"}
]
```

prompt

```
001提取excel文件的第一列”Patients “，请把1改成0001.jpg 2改成0002.jpg以此类推。
002帮我把H列和J列中的数据合写在一起，H列中的内容要在前方加上”左侧肾脏“，而J列中的内容要在前方加上”右侧肾脏“，然后将H列和J列的文字用逗号,隔开。例子：H列：上极稀疏 J列：上下极分布稀疏。合并后的内容：左侧肾脏上极稀疏，右侧肾脏上下极分布稀疏。
003帮我把I列和K列中的值改为文字描述，其中值 1为异常，0为正常。请结合002中的内容，将他们写在一起，示例：H列：上极稀疏 J列：上下极分布稀疏----> 左侧肾脏上极稀疏，右侧肾脏上下极分布稀疏.I列值为 1， J列值为1，将H I J K合并后的内容：--------> ”左侧肾脏上极稀疏，属于异常肾脏，右侧肾脏上下极分布稀疏，属于异常肾脏，综合考虑，该患者患有APN急性肾盂肾炎。”
示例：H列：正常 J列：上极放射性稀疏----> 左侧肾脏正常，右侧肾脏上极放射性稀疏.I列值为 0， J列值为1，将H I J K合并后的内容：--------> ”左侧肾脏正常，右侧肾脏上下极分布稀疏，属于异常肾脏，综合考虑，该患者患有APN急性肾盂肾炎。”
004 I列和J列，如果有一个是0，那么之后的描述不需要加“属于正常肾脏”，如果值为1，则需要在描述后加“属于异常肾脏”，最后的结论是 I列和J列的交集， 0 0 没有APN急性肾盂肾炎，0 1 患有没有APN急性肾盂肾炎，1 1 患有APN急性肾盂肾炎， 1 0患有APN急性肾盂肾炎
帮我把上述要求写入新的excel表格。请把上述内容写到一个新的excel表格中，其中第一列列名是”image“ 内容是0001.jpg 0002.jpg。。。。。 第二列列名则是”Image_description“ 内容如上所述。
```

#### 试了之后发现效果很一般啊，可能的错误！

根据你的描述，发现 **BLIP** 使用 `out = image_model.vision_model(**image_inputs).last_hidden_state` 对图像进行向量化的效果不佳，可能是由于以下原因导致的：

------

### **1. BLIP 对医学图像领域的适应性不足**

BLIP 是为通用图像和自然语言描述设计的，更多关注日常图像特征（如颜色、物体类别、场景等），而医学影像具有以下特殊性：

- **特征难以提取**：医学图像如 CT 或 MRI 中，关键特征（如肾脏边缘、纹理异常）往往较为细微，对通用视觉模型来说，这些特征可能无法有效被捕捉。
- **领域特定性**：医学影像需要捕捉领域特有的上下文特征，通用视觉模型无法很好地理解。

#### **解决方案**

- 考虑将 **BLIP 的视觉模型（如 ViT）进行微调**，使用医学影像数据集（如 NIH ChestX-ray、BraTS）来让模型适应医学场景。
- 如果微调不现实，可以直接替换 BLIP 的视觉模型为医学领域的模型，例如 **Med3D** 或 **Attention-UNet**。

------

### **2. 向量特征表示不具备全局和局部一致性**

`last_hidden_state` 通常是一个 **每个 patch 的局部特征**，它没有直接经过全局特征聚合。医学图像的细粒度特征可能因此丢失。

- 举例：如果左肾和右肾的某些特征在不同 patch 中，模型可能没有捕捉到它们的相对关系。

#### **解决方案**

- 尝试提取更高层次的全局特征：

  ```python
  out = image_model.vision_model(**image_inputs).pooler_output
  ```

  这将输出整个图像的全局表示，可能更适合检索任务。

- 将 last_hidden_state的局部特征通过平均池化或注意力机制聚合为全局特征：

  ```python
  global_feature = torch.mean(last_hidden_state, dim=1)  # 平均池化
  ```

- 融合局部和全局特征：

  ```python
  combined_feature = torch.cat([global_feature, last_hidden_state.flatten(start_dim=1)], dim=1)
  ```

------

### **3. 数据预处理不当导致特征不匹配**

BLIP 对图像的输入通常会预处理为固定分辨率（如 224x224 或 384x384）。这种处理方式可能导致医学图像的关键特征被裁剪、缩放，或丢失上下文信息。

#### **解决方案**

- 在图像预处理时，确保关键区域（如肾脏）的特征没有丢失：
  - 使用更大的输入分辨率（如 512x512），增强模型对细节的感知。
  - 如果肾脏是关键部位，可在预处理时通过分割模型提取出肾脏区域。
- 增强数据：对图像进行翻转、旋转、亮度调整等增强操作，增加模型的鲁棒性。

------

### **4. 检索匹配过程中的相似性度量问题**

BLIP 输出的图像向量与文本向量可能是高维且复杂的，常用的相似性度量（如余弦相似度）可能不足以捕捉细节。

#### **解决方案**

- 尝试其他相似性度量方法，如：

  - **欧几里得距离**：更适合表示几何特征差异。
  - **学习相似性度量**：训练一个对比学习模型，如 SimCLR、CLIP，用于优化特征对齐。

- 在检索之前，对向量进行归一化处理：

  ```python
  normalized_vector = vector / torch.norm(vector, dim=-1, keepdim=True)
  ```

------

### **5. 数据库向量与查询向量的不一致**

- 如果 BLIP 的视觉模型和语言模型在不同场景（或不同版本）下生成的向量，它们可能存在分布差异，导致检索结果不佳。

#### **解决方案**

- 确保数据库中的图像和文本向量与当前模型使用的方式一致（即，使用相同的 BLIP 模型和处理步骤）。
- 如果已有的数据库向量无法更新，可以尝试在新模型的特征空间中对其进行适配，例如通过投影头（Projection Head）对齐特征分布。

------

### **6. 数据库数据本身的单一性**

你提到数据库中的描述“较为单一”，这可能导致模型对特征的理解过于泛化。例如，如果所有图像都描述为“异常肾脏”，模型可能忽略了具体的细节。

#### **解决方案**

- 增加数据库中的文本描述的多样性，标注更多细节（如“左肾异常”或“右肾纹理分布异常”）。
- 如果标注工作量过大，可以尝试使用大语言模型（LLM）自动生成更丰富的描述。

------

### 总结

针对 BLIP 的问题，以下是建议的优化步骤：

1. **模型优化**：微调 BLIP 或替换视觉模型为适合医学影像的模型。
2. **特征提取改进**：提取全局特征，或融合局部和全局特征。
3. **数据预处理改进**：提高分辨率，确保肾脏区域的细节完整。
4. **相似性度量改进**：尝试更合适的距离度量或归一化。
5. **数据库优化**：丰富数据库中图像和文本的标注，增加多样性。

如果需要进一步的代码示例或实现细节，可以告诉我！